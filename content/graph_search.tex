\chapter{Graph Search}
\label{chap:graphSearch}
This chapter explains the basic theory necessary to understand graphs and the terminology associated with it. The later part of the chapter focuses on elaborating different graph search algorithms that are fundamental to understanding the implementation of the search algorithm in this thesis.

\section{Fundamentals}
A graph such as the one depicted in \fref{fig:graph} consists of vertices $V$ as well as edges $E$. With $G$ being a graph $V = V(G)$, is the set of vertices of the graph and $E = E(G)$, the set of Edges. Edges connect vertices of a graph. An edge of a graph can be described by ${x,y}$, as it connects the vertices $x$ and $y$. Edges that have at least one vertex in common are considered adjacent. \cite{Bollobas.1979}

Graphs can be either directed or undirected. A directed graph has unidirectional, a undirected graph bidirectional edges. In the following the word nodes and vertices might be used interchangeably.

\begin{figure}[h]
    \includegraphicsTex{MF.eps_tex}
    \caption{Graph theory explanation}
    \label{fig:graph}
\end{figure}

\subsection{State Space of a Graph}
While the chapter is termed graph search one has to understand that this term can be seen as the search for a set of actions that changes the state of an object from an initial state to a desired goal state. Given this general description graph search algorithms can be applied to a great variety of problems from motion planning to artificial intelligence \cite{LaValle.2006}.

The following definition constitutes a general description of the state space of a graph, it is borrowed from Lavalle's famous book titled \emph{Planning Algorithms}. 

\begin{enumerate}
    \item A nonempty \textit{state space} $x \in X$, which is finite or countably infinite set of \textit{states}.
    \item For each \textit{state} $x \in X$, a finite action space $U(x)$.
    \item A \textit{state transition function f} that produces a state $f(x,u) \in X$ for every $x \in X$ and $u \in U(x)$. The \textit{state transition equation} is derived from $f$ as $x' = f(x,u)$.
    \item An \textit{initial state} $x_s \in X$.
    \item A \textit{goal set} $X_G \subset X$.
\end{enumerate}

The vertices $V$ of the graph $G$ can be considered the state space $X$ of the $G$. Thus, each vertex holds information pertaining to a specific state. The edges $E$ are best represented by the action space $U$. Where an edge $u \in U(x)$ transitions a state $x \in X$ to a state $x' \in X$ with the state transition function $f(x,u)$.

\subsection{Open and Closed Lists}
For the explanation of the following algorithms two types of lists need special attention. On the one side there is the open list $O$, representing the set of the search frontier, the vertices, that have not yet been expanded, but have an adjacent vertex that has been expanded, hence any vertex $v_i \in O$ is part of the frontier. On the other side there is the closed list $C$, representing the set of vertices that have already been expanded.

\subsubsection{Priority Queues}
% Lavalle General Forward Search
Depending on the algorithm these lists need to implemented as a priority queue. A priority queue is a data structure that sorts a set by a key either from large to small or vice versa. The following operations are supported by the basic priority queue. All these actions maintain the order of the queue \cite{Skiena.2008}.

\begin{itemize}
    \item insertion of a given item with a given key
    \item find the minimum of the keys of the items in the queue
    \item delete the item with the minimum key from the queue
\end{itemize}

The type of queue chosen has a considerable impact on the time complexity for the operations mentioned above. When implementing a queue it is recommended to take this into consideration, as a more complex queue might yield considerable better performance, especially when operating on larger sets of data. \footnote{While C++ implements a basic priority queue in the \emph{std} name space \url{http://en.cppreference.com/w/cpp/container/priority_queue} other more advanced queues (Binomial, Fibonacci, etc.) can for example easily implemented with a library such as \emph{Boost} \url{http://www.boost.org/doc/libs/1_60_0/doc/html/heap.html}}

\subsection{Heuristics}
In order to find an optimal path the search needs to be systematic. Various search algorithms differ most significantly in the way they expand vertices \cite{LaValle.2006}. To avoid wasteful search of unpromising regions of a graph the search must be as informed as possible, only expanding nodes that have the potential to belong to the optimal path \cite{Hart.1968}. If the search uses information that leads to skipping the expansion of a specific node, hence failing to find the optimal path, admissibility is forfeited.

Heuristics are used as an aid for approximating a solution in order to address the limitations of processing power, in some cases drastically reducing the search space. A finite amount of time only allows for a finite number of calculations. Although this comes without a suprise it still is a major limitation to problems that grow exponentially with search depth. While searching a graph the search needs to decide which vertex to expand and which edge to take. Information that aims to answer this question is considered a heuristic. A heuristic might be based on some cost estimates between the current vertex and the goal vertex. \cite{Newell.1976} 

A heuristic is a function that provides the necessary information that allows the algorithm to converge faster towards the goal. Only an admissible heuristic can lead to optimal results \cite{Hart.1968}.

\subsection{Optimality}
One of the great advantages of graph search algorithms compared to other approaches for path planning is that many algorithms are proven to be optimal. Bellman's principle of optimality reads below.
\begin{quotation}
    \noindent \emph{An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.} \cite{Bellman.2003}
\end{quotation}

In essence any optimal solution for a problem that requires a sequence of decisions can only consist of optimal sub-solutions.

\begin{lemma}
    Given a weighted, directed graph $G = (V,E)$ with a cost function $g$: $E \rightarrow \mathbb{R}$ let $p = \{v_0, v_1,\ldots, v_k\}$ be a shortest path from vertex $v_0$ to vertex $v_k$ and, for any $i$ and $j$ such that $0 \leq i \leq j \leq k$, let $p_{ij} = \{v_i, v_{i+1},\ldots, v_j\}$ be the sub path of $p$ from vertex $v_i$ to vertex $v_j$. Then, $p_{ij}$ is a shortest path from $v_i$ to $v_j$.
\end{lemma}
 
\begin{proof}
    If we decompose the path $p$ into $v_0 \xrightarrow{p_{0i}} v_i \xrightarrow{p_{ij}} v_j \xrightarrow{p_{jk}} v_k$, then we have that $g(p) = g(p_{0i}) + g(p_{ij}) + g(p_{jk})$. Now, assume that there is a path $p'_{ij}$ from $v_i$ to $v_j$ with cost $g(p'_{ij}) < g(p_{ij})$. Then, $v_0 \xrightarrow{p_{0i}} v_i \xrightarrow{p'_{ij}} v_j \xrightarrow{p_{jk}}$ is a path from $v_0$ to $v_k$, that has a lesser cost $g(p_{0i}) + g(p'_{ij}) + g(p_{jk})$ than $g(p)$, which contradicts the assumption that $p$ is the shortest path from $v_0$ to $v_k$. \cite{Cormen.2009}
\end{proof}

\subsection{Admissibility and Consistency}
Algorithms that find optimal paths on non-negative graphs are considered admissible \cite{Hart.1968}. Algorithms that are using heuristic estimates need to use heuristics that never overestimates the cost in order to be considered admissible \cite{Russell.2010}. It is clear, that the Euclidean distance between two points in $R^2$ is admissible since the shortest distance between two points in is a straight line.

Consistency of a heuristic implies, that the heuristic estimate for reaching the goal vertex from a vertex $v$ must be less or equal to the estimate for $v'$ plus the action cost,  $h(v) \leq c(v, u, v')+ h(v')$. This is a case of the triangle inequality, which constitutes that each side of a triangle cannot be longer than then sum of the other two sides. \cite{Russell.2010}

\subsection{Completeness}
Algorithms that find a solution if a solution exists or correctly report that there is no solution to the problem are considered complete. \cite{LaValle.2006,Russell.2010}

\section{Breadth First Search}
Breadth First Search (BFS) was first developed by Moore and published by Lee in 1961 \cite{Lee.1961}. The BFS algorithm works on unweighted graphs (graphs with equal edge costs). In the original paper BFS is described by the author as ``a computer model of waves expanding from a source under a form of straight-line geometry''. BFS traverses a graph layer by layer, all vertices with depth $k$ in the graph are visited before it proceeds to vertices with depth $k+1$.

BFS does not consider edge costs, but only the number of expansions and can hence only be used on non-weighted graphs. On these graphs however BFS is complete and optimal, although the time and memory complexity is high, as the search is not guided \cite{Lee.1961,LaValle.2006} .

BFS traverses all vertices $V$ in a graph $G$ until the algorithm terminates (e.g. due to meeting a goal condition). While the search progresses every vertex $x \in V$ changes its state from undiscovered to discovered. In order to trace the route discovered by BFS, a direction and hence a predecessor is assigned to each vertex. The start vertex will thus be the root of the resulting tree of successor. This is the key property that makes BFS a suitable candidate to solve shortest path problems \cite{Skiena.2008}. \Fref[plain]{alg:BFS} depicts the structure of the search. BFS expands vertices in a \textit{first in, first out} system, the closed list $C$ is used to avoid unnecessary expansion of vertices that have previously been visited.

\begin{algorithm}
    \caption{Breadth First Search}\label{alg:BFS}
    \begin{algorithmic}[1]
        \Require $x_s \cap x_g \in X$
        \State $O = \emptyset$
        \State $C = \emptyset$
        \State $Pred(x_s) \gets null$
        \State $O.push(x_s)$
        \While{$O \neq \emptyset$}
            \State $x \gets$ O.pop()
            \State $C.push(x)$
                \For {$u \in U(x)$}
                    \State $x_{succ} \gets f(x,u)$
                    \If {$x_{succ} \notin C$}
                        \If {$x_{succ} \notin O$}
                            \State $Pred(x_{succ}) \gets x$
                            \If{$x_{succ} = x_g$}
                                \State \textbf{return} $x_{succ}$
                            \EndIf
                            \State $O.push(x_{succ})$
                        \EndIf
                    \EndIf
                \EndFor
        \EndWhile
        \State \textbf{return} null
    \end{algorithmic}
\end{algorithm}

\section{Dijkstra's or Uniform-Cost Search}
While Breadth First Search delivers optimal solutions to the discrete path planning problem it does not consider edge cost and is hence in its original form only applicable to uniform cost graphs. Dijkstra's search algorithm can be seen somewhat of a refinement, even though first published two years earlier than BFS, in 1959. This section is also called \emph{Uniform-Cost Search} as people such as Felner have pointed out that the original Dijkstra's algorithm was much closer to UCS than it is often conveyed in today's textbooks \cite{Felner.2011}. In his original paper Dijkstra indirectly refers to Bellman's principle of optimality, which is a needed proof for the algorithm being optimal.

Dijkstra's algorithm begins to divide all vertices into three sets, the closed set $C$, the open set $O$ (implemented as a priority queue) as well as the remaining vertices. At the beginning $C$ and $O$ are the empty sets. After this the algorithm starts as depicted in \fref{alg:Dijkstra} \cite{Dijkstra.1959}. First the start vertex $x_s$ gets transferred to the open set. Next the while loop is entered, line \ref{alg:DijkstraWhile}, which either returns the goal vertex (line \ref{alg:DijkstraSolution}) or null if the $O$ is the empty set. When a vertex gets expanded it is removed from $O$ and added to $C$. Afterwards all edges connected to the vertex are evaluated and the vertexes they connect to. If any of these vertexes are not in $C$ then we calculate the \textit{cost-so-far} the same $g(x') = g(x) + l(x,u)$. Where $g(x)$ represents the \textit{cost-so-far} for the vertex $x$ from the start vertex and $l(x,u)$ the cost for the state transition from $x$ to $x'$ given the action $u$. If the resulting cost is lower than the current cost to reach that vertex or that vertex is not an element of $O$, the predecessor and the cost for that vertex will be set and the position in the priority queue will be decreased or it will added to $O$ respectively. \cite{Dijkstra.1959,LaValle.2006,Cormen.2009} 

\begin{algorithm}
    \caption{Dijkstra's Search}\label{alg:Dijkstra}
    \begin{algorithmic}[1]
        \Require $x_s \cap x_g \in X$
        \State $O = \emptyset$
        \State $C = \emptyset$
        \State $Pred(x_s) \gets null$
        \State $O.push(x_s)$
        \While{$O \neq \emptyset$} \label{alg:DijkstraWhile}
            \State $x \gets$ O.popMin()
            \State $C.push(x)$
            \If{$x = x_g$}
                \State \textbf{return} $x$ \label{alg:DijkstraSolution}
            \Else
                \For {$u \in U(x)$}
                \State $x_{succ} \gets f(x,u)$
                    \If {$x_{succ} \notin C$}
                        \State $g \gets g(x) + l(x,u)$
                        \If {$x_{succ} \notin O$ \textbf{or} $g < g(x_{succ})$}
                            \State $Pred(x_{succ}) \gets x$
                            \State $g(x_{succ}) \gets g$
                            \If {$x_{succ} \notin O$}
                                \State $O.push(x_{succ})$
                            \Else
                                \State $O.decreaseKey(x_{succ})$
                            \EndIf
                        \EndIf
                    \EndIf
                \EndFor
            \EndIf
        \EndWhile
        \State \textbf{return} null
    \end{algorithmic}
\end{algorithm}

\section{A* Search}
If one thinks of Dijkstra's search as a refinement of BFS then A* Search can be seen as a refinement of Dijkstra's work. While Dijkstra associated a \textit{cost-so-far} $g$ with each vertex of a graph to determine the next vertex to expand, A* enhances the algorithm by the use of a heuristic, allowing for much more rapid convergence under certain conditions, while still ensuring its optimality \cite{Hart.1968}. The heuristic $h(x)$ is the  \textit{cost-to-come}, based on an estimate of the cost from state $x$ to the goal state $x_g$. Just as Dijkstra's algorithm A* also starts with $O$ and $C$ being the open and closed list respectively. Just as Dijkstra's algorithm A* the starts with a empty closed set $C$ open set $O$. The search is depicted in \fref{alg:A*} the key difference happens in line \ref{alg:A*Heuristic}, here the heuristic estimate comes into play so that the cost for a state $x$ is thus $f(x) = g(x) + h(x)$ by which the priority queue will be sorted. A standard heuristic estimate that can speed up search significantly, while maintaining admissibility and thus optimality, is the Euclidean norm for two dimensional problems.

\begin{algorithm}
    \caption{A* Search}\label{alg:A*}
    \begin{algorithmic}[1]
        \Require $x_s \cap x_g \in X$
        \State $O = \emptyset$
        \State $C = \emptyset$
        \State $Pred(x_s) \gets null$
        \State $O.push(x_s)$
        \While{$O \neq \emptyset$}
            \State $x \gets$ O.popMin()
            \State $C.push(x)$
            \If{$x = x_g$}
                \State \textbf{return} $x$
            \Else
                \For {$u \in U(x)$}
                \State $x_{succ} \gets f(x,u)$
                    \If {$x_{succ} \notin C$}
                        \State $g \gets g(x) + l(x,u)$
                        \If {$x_{succ} \notin O$ \textbf{or} $g < g(x_{succ})$}
                            \State $Pred(x_{succ}) \gets x$
                            \State $g(x_{succ}) \gets g$
                            \State $h(x_{succ}) \gets Heuristic(x_{succ}, x_g)$ \label{alg:A*Heuristic}
                            \If {$x_{succ} \notin O$}
                                \State $O.push(x_{succ})$
                            \Else
                                \State $O.decreaseKey(x_{succ})$
                            \EndIf
                        \EndIf
                    \EndIf
                \EndFor
            \EndIf
        \EndWhile
        \State \textbf{return} null
    \end{algorithmic}
\end{algorithm}

\newpage
\section{Hybrid A* Search}\label{sec:HA}
The hybrid A* algorithm\footnote{The naming has not been consistent, variants are: hybrid A* and hybrid-state A*} was successfully used in the DARPA Urban Challenge, a robot competition organized by the U.S. Government in 2007. In the following years insights to the algorithm were given by Dolgov et al. in \cite{Montemerlo.2008,Dolgov.2008,Dolgov.2009,Dolgov.2010}. The hybrid A* algorithm behaves similar to the A* algorithm. The key difference is, that state transitions happen in continuous rather than discrete space. One of the largest drawbacks of the previous approaches for path planning of non-holonomic robots is that the resulting paths are discrete and thus often not executable as changes of direction are sudden rather than smooth \cite{Montemerlo.2008,Dolgov.2010}.

While the hybrid A* search implicitly builds the graph on a discretized grid, vertices can reach any continuous point on the grid. As a continuous search space would not be finite a discretization in form of grid cells is taken, limiting the grow of the graph. Since transitions from vertex to vertex have no predefined form it is easy to incorporate the non-holonomic nature in the state transition. The search space is usually three dimensional so that the state space $X$ consists of $x,y,\theta$, creating a discretized cuboid with the base representing the $x,y$ position and the height the heading $theta$ of a vertex.

\Fref{alg:HA*} outlines the steps in the hybrid A* search. Just as the ordinary A* search, it starts by defining the empty sets $O$ and $C$, as well as by setting the predecessor state of the start state to $null$ and pushing the start state on the open list, line \ref{alg:HA*start}. At line \ref{alg:HA*while} the \textit{while} loop starts, which only terminates if the open list is empty or the goal state has been reached, line \ref{alg:HA*solution} since a goal state might not be reached exactly the function \textit{RoundState} in \ref{alg:HA*solution} is used to round both the current as well as the goal state before comparison.
If the current vertex being expanded is no the goal vertex new successors will be generated for all available actions $u  \in U(x)$, line \ref{alg:HA*successor}. Is the successor is not in $C$, then the \textit{cost-so-far} for the vertex are calculated. If the vertex is not in $O$ or the \textit{cost-so-far} are smaller than the cost for a vertex with the same index, that is also part of the $O$ then the successor will be assigned a pointer to its predecessor, the \textit{cost-so-far} and the \textit{cost-to-come} will be updated. After that the vertex is pushed on the open list or the key is decreased using the new value $f(x_{succ})$.
It is important to note, that even though hybrid A* is rounding the state in order to prune branches that are similar, the expansion will always happen from the actual value of the state as opposed to the rounded one.

\begin{figure}[h]
    \includegraphicsTex{searchComparison.pdf_tex}
    \caption{Dijkstra's Algorithm and A*}
    \label{fig:searchComparison}
\end{figure}

%\paragraph{Notations}
%\begin{itemize}
%    \item start state $x_s \in X$
%    \item goal state $x_g \in X$
%    \item open list, implemented as priority queue $O$
%    \item closed list $C$
%    \item cost so far $g(x,x_s)$
%    \item cost to go $h(x,x_g)$
%    \item total estimated cost $f(x) = g(x,x_s) + h(x,x_g)$
%\end{itemize}

\begin{algorithm}
    \caption{Hybrid A* Search}\label{alg:HA*}
    \begin{algorithmic}[1]
        \Function{roundState}{$x$}
            \State $x.Pos_X = \max\{m\in\mathbb{Z}\mid m\le x.Pos_X\}$
            \State $x.Pos_Y = \max\{m\in\mathbb{Z}\mid m\le x.Pos_Y\}$
            \State $x.Ang_\theta\ =\max\{m\in\mathbb{Z}\mid m\le x.Ang_\theta\}$
            \State \textbf{return} $x$
        \EndFunction
        \Statex
        \Function{exists}{$x_{succ}$,$\calL$}
            \If{$\{ x \in \calL \mid roundState(x) = roundState(x_{succ})\} \neq \emptyset$}
                \State \textbf{return} true
            \Else
                \State \textbf{return} false
            \EndIf
        \EndFunction
        \Statex
        \Require $x_s \cap x_g \in X$
        \State $O = \emptyset$ \label{alg:HA*start}
        \State $C = \emptyset$
        \State $Pred(x_s) \gets null$
        \State $O.push(x_s)$
        \While{$O \neq \emptyset$} \label{alg:HA*while}
            \State $x \gets$ O.popMin()
            \State $C.push(x)$
            \If{$roundState(x) = roundState(x_g)$} \label{alg:HA*solution}
                \State \textbf{return} $x$
            \Else
                \For {$u \in U(x)$}
                \State $x_{succ} \gets f(x,u)$\label{alg:HA*successor}
                    \If {$\neg exists(x_{succ},C)$}
                        \State $g \gets g(x) + l(x,u)$
                        \If {$\neg exists(x_{succ},O)$ \textbf{or} $g < g(x_{succ})$}
                            \State $Pred(x_{succ}) \gets x$
                            \State $g(x_{succ}) \gets g$
                            \State $h(x_{succ}) \gets Heuristic(x_{succ}, x_g)$
                            \If {$\neg exists(x_{succ},O)$}
                                \State $O.push(x_{succ})$
                            \Else
                                \State $O.decreaseKey(x_{succ})$
                            \EndIf
                        \EndIf
                    \EndIf
                \EndFor
            \EndIf
        \EndWhile
        \State \textbf{return} null
    \end{algorithmic}
\end{algorithm}